\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[round]{natbib}
\usepackage{amsthm}
\usepackage{amssymb}
\theoremstyle{definition}
\newtheorem{ftsdef}{Definition}

\title{Dissertation}
\author{Michael Gallagher}

\begin{document}


\maketitle

\tableofcontents

\section{Introduction}

\subsection{Objectives}

fuzzy vs crisp. EMH. TA. different time periods. Different securities

\subsubsection{Fuzzy Pattern Matching}

Fuzzy logic is still a new field of interest but with a wide range of applications. There is still much room for research that demonstrates the differences in performance between using a fuzzy logic system and using a traditional crisp logic system... (Need to actually do both then!)

\subsubsection{Technical Analysis}

There is still much debate as to whether analysis of previous price action can be used to determine future price performance...

\section{State of the Art}

\subsection{Fuzzy Time Series}

\cite{box2013time} describes a time series as ``a sequence of observations taken sequentially in time''. A graph of stock price, the inventory of an item at a warehouse, the height of a river or the temperature for an area could be considered a time series of data. A core feature of a time series is that typically adjacent observations are dependent, such that the value of the observation at time $t$ is somewhat dependent on the value at time $t-1$. The practical implications of this feature is that through time series analysis it is possible to model a time series and use this model to forecast observations.

A fuzzy time series is a model of a time series that uses fuzzy set theory to find relationships between points on the time series and use these relationships to forecast observations. According to \cite{chen1996forecasting}, "the main difference between a a fuzzy time series and conventional time series is that the values of the former are fuzzy sets and the latter are real numbers". The concept of fuzzy time series was proposed by by \cite{song1993forecasting, song1994forecasting} when they proposed a model to forecast enrolment at the University of Alabama. Their motivation was to ``find ways of modelling a special dynamic process whose observations are linguistic values instead of numerical ones''. 

\subsubsection{Definitions}

The following definitions for a first order fuzzy time series model are provided by \cite{chen1996forecasting}, \cite{chen1996forecasting} and \cite{chu2009fuzzy}.

\begin{ftsdef}
Let $Y(t)(t= \ldots,0,1,2, \ldots)$, a subset of $\mathbb{R}$, be the universe of discourse on which fuzzy sets $f_i(t)(i=1,2,\ldots)$ are defined and let $F(t)$ be a collection of $f_i(t)(i=1,2,\ldots)$. Then $F(t)$ is called a fuzzy time series on $Y(t)(t= \ldots,0,1,2, \ldots)$.
\end{ftsdef}
In this definition, $Y(t)$ represents a time series, returning a value at different points along time $t$. The range of values in this time series is called the universe of discourse. $f_i(t)$ are fuzzy sets over the universe of discourse, consisting of the all the linguistic terms defined in the universe and the membership of each term in that fuzzy set. $F(t)$ is the collection of all of these fuzzy sets. This collection of fuzzy sets at any point $t$ on a time series is called a fuzzy time series.

As an example, consider a graph of the the daily closing stock price for a company. $Y(t)$ is the closing stock price at any day $t$. The universe of discourse is the range of values you are considering at this time, so if your model was considering the prices over the past 100 days, then your universe of discourse would be the range of numbers between the highest and lowest points in the past 100 days. 

This example considers one linguistic variable which indicates the performance of a stock. The universe of discourse is partitioned into separate intervals, $u_1, u_2,\ldots,u_k$. For example, if the universe of discourse was the range in dollars $[100, 200]$, 5 intervals might be used where $u_1 = [100 \ldots 120]$, $u_2 = [120 \ldots 140]$, $u_3 = [140 \ldots 160]$, $u_4 = [160 \ldots 180]$ and $u_5 = [180 \ldots 200]$. Fuzzy sets are then defined which are the linguistic values of the linguistic variable ``performance". For example, 5 fuzzy sets are defined, $very\_low$, $low$, $mid$, $high$ and $very\_high$. These fuzzy sets consist of the grade of membership of each interval in the fuzzy set. For example:
\begin{description}
\item[] $very\_low = 1/u_1 + 0.5/u_2 + 0/u_3 + 0/u_4 + 0/u_5$
\item[] $low = 0.5/u_1 + 1/u_2 + 0.5/u_3 + 0/u_4 + 0/u_5$
\item[] $med = 0/u_1 + 0.5/u_2 + 1/u_3 + 0.5/u_4 + 0/u_5$
\item[] $high = 0/u_1 + 0/u_2 + 0.5/u_3 + 1/u_4 + 0.5/u_5$
\item[] $very\_high = 0/u_1 + 0/u_2 + 0/u_3 + 0.5/u_4 + 1/u_5$
\end{description}

$F(t)$ the time series of these fuzzy sets, and can be regarded as a linguistic variable.

\begin{ftsdef}
Suppose $F(t)$ is caused by $F(t-1)$ only, then this fuzzy relation can be expressed as $F(t)=F(t-1) \circ R(t,t-1)$, where $R(t,t-1)$ is the fuzzy relationship between $F(t-1)$ and $F(t)$. The model $F(t)=F(t-1) \circ R(t,t-1)$ is called the first order model $F(t)$.
\end{ftsdef}

Definition 1 shows that $F(t)$ is a linguistic variable with linguistic values $f_i(t) (i=1,2,\ldots)$. Definition 2 states that, for a first order fuzzy time series, for every linguistic value in the $F(t)$, there is a relationship $R$ between $F(t-1)$ and $F(t)$. 

This means that there is a relationship between the linguistic value for $F(t)$ at every point in time and the next point in time. Following from the previous example, consider the fuzzy time series $F(t)(t=1,2,\ldots,6)$ where $f(1)=low$, $f(2)=high$, $f(3)=med$, $f(4)=low$, $f(5)=low$ and $f(6)=very\_high$, then the fuzzy logic relationships can be shown as follows: 

\begin{table}[h]
	\center
	\begin{tabular}{ l l l }
  	$low \rightarrow high$  \\
  	$high \rightarrow med$ \\
  	$med \rightarrow low$ \\
  	$low \rightarrow low$ \\
  	$low \rightarrow very\_high$ \\
	\end{tabular}
	\caption{Fuzzy Logical Relationships}
\end{table}

\begin{ftsdef}
All fuzzy logical relationships in the fuzzy time series can be further grouped together into fuzzy logical relationship groups according to the same left-hand sides of the fuzzy logical relationship.
\end{ftsdef}

This definition states that for every fuzzy logical relationship between $F(t)$ and $F(t-1)$, as in Definition 2, the relationships over the time series may be grouped in relationships where $F(t-1)$ are the same. The fuzzy logical relationship groups for the example can be shown as follows:

\begin{table}[h]
	\center
	\begin{tabular}{ c c c c }
  	Group 1: & $low$ & $\rightarrow$ & $high, low, very\_high$ \\
  	Group 2: & $high$ & $\rightarrow$ & $med$ \\
  	Group 3: & $med$ & $\rightarrow$ & $low$ \\
	\end{tabular}
	\caption{Fuzzy Logical Relationship Groups}
\end{table}

These relationships are then used to forecast observations in time. Taking $t$ as the point in time to be forecast, we can predict $F(t)$ using the fuzzy logic relationship grouping for $F(t-1)$. If there is only 1 fuzzy logic relationship for $F(t-1)$, then that relationship is used for the forecast. Continuing from the example, if $F(t-1)$ is $high$, then Group 2 is referenced, and the only right-hand side value, $med$, is used as the forecast. Various solutions have been proposed in the case that there is more than one outcome on the right-hand side of a fuzzy logical relationship group, as with Group 1, including max-min composition as proposed by \cite{song1993forecasting} and simple arithmethic operations as proposed by \cite{chen1996forecasting}.

\begin{ftsdef}
Suppose $R(t,t-1)$ is a first order model of $F(t)$. If for any $t$, $R(t,t-1)$ is independent of $t$, that is for any $t$, $R(t,t-1) = R(t-1,t-2)$, then $F(t)$ is called a time-invariant fuzzy time series or else it is called a time-variant fuzzy time series.
\end{ftsdef}

This definition defines a time invariant and a time-variant fuzzy time series. By this definition a time-variant fuzzy time series is one where the relation between values $F(t)$ and $F(t-1)$ is never the same as the relation between $F(t-1)$ and $F(t-2)$. Combining this with Definition 2, a time-variant fuzzy time series is one in which $F(t)$ and $F(t-1)$ never have the same fuzzy values. 

Practically, most sufficiently large fuzzy time series will have consecutive fuzzy values, and as such will be time-invariant fuzzy time series. \cite{song1993forecasting} provides a theorem that implies that ``in the case of a time-invariant, it is very easy and convenient to calculate the first order model''.

\subsubsection{Proposed Models}

The typical use of a fuzzy time series is to forecast observations on the time series using historical data. Studies using fuzzy time series have been carried out on forecasting university enrolment \citep{song1993forecasting, song1994forecasting, chen1996forecasting, chen2002forecasting, chen2004new, cheng2006trend, lee2006pattern, huarng2006ratio, tsaur2012fuzzy}, Stock Market price \citep{huarng2005type, cheng2006trend, lee2006pattern, huarng2006ratio, Chen2007fib, chu2009fuzzy}, Foreign-Exchange rates \citep{tsaur2012fuzzy} and temperature \citep{temperatureprediction2000, lee2006pattern}.

\cite{song1993forecasting} pioneered the fuzzy time series model providing the definitions for the concept and a method for modelling a time invariant fuzzy time series. The method was shown to be better than the Linear Regression Method for forecasting student enrolments at the University of Alabama. It followed a similar series of steps as the example provided with the definitions, but has the key difference of defining relations between fuzzy values using max-min composition, and thus matrix operations. They also use a simple defuzzification algorithm to interpret the results, to which they claim ``it is not difficult to jump to the conclusion that in the interpretation of the output results, experience knowledge is still needed''. The process is as follows:

\begin{enumerate}
 \item If the membership of an output has only one maximum, then select the midpoint of the interval corresponding to the maximum as the output value
 \item If the membership of an output has two or more consecutive maximums, then select the midpoint of the corresponding conjunct intervals as the output
 \item Otherwise, use the standardised membership and the midpoint of each interval to calculate the ``mean'' using $\sum S_i M_i$ where $S_i$ is the standardised membership and $M_i$ the midpoint of interval $i$. This mean will be taken as the output value
\end{enumerate} 
 
\cite{chen1996forecasting} made improvements to the model used by \cite{song1993forecasting} by using simplified mathematical operations instead of computationally expensive max-min composition for defining fuzzy relations. 

[define the composition Song did according to section 3 of chen, then talk about the simplified method, and possibly give the step by step for the whole thing - have to do it somewhere, and cheng seems to think it's a good base model to define]

\subsection{Technical Analysis}

Technical Analysis is a form of financial analysis where past price behaviour is used to predict future price behaviour in financial markets \cite{foundations} say that ``the general goal of Technical Analysis is to identify regularities in the time series of prices by extracting non-linear patterns from noisy data''. Examples of this form of analysis include identifying trends in a graph of price movement, or concluding that a price is unlikely to go lower than the 52-week low.

\subsubsection{History}

The use of this form of analysis has been documented for several hundred years. One of the first uses of Technical Analysis dates back to Japan in the 18th Century AD. In 1710 Japan's rice market had matured enough to begin use rice coupons instead of trading physical rice. Their receipts were traded constituting the first Futures trades ever recorded \citep[p.15]{jcct1991}. 

Munehisa Homma was a rice merchant in Japan, who amassed great wealth trading these rice coupons and is sometimes credited as the Father of Japanese Candlestick Charting. Although it is unclear whether Homma actually used Japanese Candlestick Charting techniques, it is recorded that he used the history of price movement to gauge the emotions of the market at the time, ``When all are bearish, there is cause for prices to rise. When everyone is bullish, there is cause for the price to fall''. Following Homma different charting techniques were introduced, until the introduction and popularisation of Japanese Candlestick Charting for Technical Analysis in the mid 19th Century \citep[p.18]{jcct1994}.

In the west, Dow Theory was developed and expanded on in the early 20th Century, leading to works \citep{edwards2012technical} that directly influence Technical Analysis today.

Even with such a diverse history the use of Technical Analysis is still a hotly debated topic. Experts and Academics are divided in its use \citep{foundations}, the influential \textit{A Random Walk down Wall Street} concluding it is as valid as Alchemy when put under scientific scrutiny \cite[p.159]{randomwalk2012}. Nonetheless, it appears a significant number of analysts incorporate Technical Analysis, with a study by \cite{examininguse1997} finding a mean importance of 35\% was given to Technical Analysis by respondents in various investment banks, and \cite{cheung2000currency} characterising 30\% of Foreign-Exchange traders as Technical Traders. 

\subsubsection{Efficient Market Hypothesis}

One explanation for this debate is that Technical Analysis appears to contradict the widely accepted Efficient Market Hypothesis. The Efficient Market Hypothesis claims that the price of a security is extremely efficient at reflecting the information about that security. When news becomes public the market will very efficiently arrive at a price for the security that reflects the impact of the news. This claim has major consequences, such that both Technical Analysis and Fundamental Analysis, which is analysing the health of a security by viewing information such as company earnings, are unable to help an investor achieve a greater profit than if a random selection of securities were invested in \citep{emhAndCritics}. 

While there is still a lot of support for this model, strict adherence to it does not offer the complete picture. If the markets were perfectly efficient then the price would simply jump between points as individual news was released. In reality there is a large amount of noise, volatility and uncertainty in the market. Very often it is not clear what impact some news should have. And of course the accuracy of market information and the availability of the information to the public add further uncertainty to the price movement.

The Random Walk Hypothesis says that even with these movements in price the market is still informationally efficient. It proposes that the price of a security represents a 'random walk' around its intrinsic value, and consequently that price movements can not be predicted. \cite{lo1988} reject this hypothesis however, but note that ``this rejection does not necessarily imply the inefficiency of stock-price formulation''.

One theory is that these uncertainties in price movement allow Technical Analysis to be utilised. \cite{indefenseof} show that past prices combined with other information, such as non-public information, can achieve unusual profit. They claim that non-price information creates opportunity that can be efficiently exploited using Technical Analysis. As non-public information is revealed to an investor, it is unclear as to the extent that this information has been revealed. If the investor knows the behaviour that a market would demonstrate if this information was widely distributed, he or she could examine the past price movements and determine a probability that the information has been revealed, and thus determine if there is still opportunity for a profitable investment.

While this demonstrates a use for past price data, it only demonstrates use when combined with other valuable information, and thus does not contradict the Efficient Market Hypothesis which only states that attempting to make profits by exploiting currently available information is futile \citep{taprofitability}.

So why is Technical Analysis still widely used if it contradicts popular financial theory? There are many possible explanations for this, as while there may be a lack of strong statistical evidence for its effectiveness, it is also far from debunked. 	

\subsubsection{Human Perception}

One of several explanations by \cite[p.45-71]{aronson2011evidence} is that humans suffer cognitive biases when determining the significance of visual patterns in their analysis. Many experts believe they can spot visual pa	tterns such as price trends on a graph, and would take the claim that these trends are irrelevant as ridiculous. Technical Analysts take the significance of these patterns for granted. However when developing or practising a trading system based on patterns, they can succumb to confirmation bias by giving a higher significance to evidence that supports the pattern they're looking for as opposed to evidence for other patterns that might be available. Also when determining the efficacy of these systems based on past data, hindsight bias can lead to certain patterns appearing obvious after their formation. This leads an expert to think this pattern is easily detectable, even though while the pattern was forming the evidence for that particular pattern was indecisive, and possibly pointed to other, contradictory patterns \cite[p.62]{aronson2011evidence}.

Another explanation is that Technical Analysis appeals to behavioural psychology. If a large amount of investors are searching for similar patterns, then the outcome following these patterns may become a self-fulfilling prophecy. A study by \cite{examininguse1997} finds that 49\% of Foreign-Exchange Technical Analysts explicitly cite this as a reason. These points are disputed by Malkiel however, stating "The problem is that once such a regularity is known to market participants, people will act in a way that prevents it from happening in the future" \cite[p.162]{randomwalk2012}.

\subsubsection{Academic Research}

These explanations aren't really enough to justify such widespread acceptance, but they do demonstrate factors that might encourage someone to adopt a technical trading strategy. Fortunately in recent years academics have produced a significant amount of literature on the subject.

\cite{taprofitability} performed a survey of 95 studies of technical trading strategies from between 1988 and 2004. Among these, 56 found positive results, 20 obtained negative results and 19 indicated mixed results. Although there is a significant number of studies before this date, they note that prior to \cite{lukac1988} studies suffered from a number of problems, which \cite{brock1992} summarises as:
\begin{enumerate}
\item Relatively short time periods being examined 
\item Studies generally not computing significance levels 
\item Studies suffering from data snooping bias by being designed and tested on the same data
\end{enumerate}

\cite{taprofitability} say modern studies improve on this as they ``typically
increase the number of trading systems tested, assess risks of trading rules,
perform statistical tests with either conventional statistical tests or more sophisticated bootstrap methods, or both, and conduct parameter optimization and out-of-sample verification''.

But the question still remains, with so much positive evidence and theoretical explanations, why is the use of Technical Analysis still such a controversial issue among Professionals and Academics? 

In the professional world, it could be due to the difficulty in experimentally verifying some Technical Analysis techniques, many of which rely on visual cues in the eyes of an Expert. This subjectivity as to the existence of a pattern can sometimes lead to experts viewing differently or disagreeing about certain patterns, fuelling a controversy that Technical Analysis is nothing more than pseudo-analysis. Also with most studies finding some technical trading strategies successful and many unsuccessful, it might be perceived as safer to ignore Technical Analysis altogether.

In the Academic world, \cite{taprofitability} point to \cite{assetpricing} who says that ``trading rules that reliably survive transactions costs and do not implicitly expose the investor to risk have not yet been reliably demonstrated''. They interpret this to mean that the scepticism is due to data snooping problems, and insignificant profits after taking adjustments for transaction costs and risk.

Data snooping is a difficult issue to address, but studies more recent than those surveyed by \cite{taprofitability} have addressed this issue to some extent.

[Discussion of studies since 2004]

\subsubsection{Techniques}

There are many trading strategies that use Technical Analysis. Almost any strategy that uses past price movement or behaviour as an indicator for future price counts as a technical trading strategy. Discussed here are 3 techniques that are seen to be widely used in technical trading strategies.

\begin{itemize}
\item Moving averages are graph lines that indicate the average price over a fixed period. Different functions can also be used such as calculating a weighted moving average. Its purpose is to smooth the noise in a graph and to identify a trend. A moving average cross is where 2 moving averages are used on a graph, generally with one having a short period indicating current trend and one having a long period indicating overall trend. When the line of the short period crosses the line of the long period it is an indication of a change in trend \citep{brock1992}. Moving averages have been used in many studies on technical trading strategies, with generally positive performance. \cite{taprofitability} found moving average rules showed consistently profitable results in the foreign exchange and futures market, and the most reliable performance in the stock market out of the methods tested.

\item Technical Patterns are visual patterns that appear in a graph of price movement. A Head-and-Shoulders pattern is one where the price represents a persons head an shoulders, where the price shows an approximately symmetrical sequence of five local extrema which correspond to 2 shoulders, 2 necks and a head. The outcome of this pattern is that the price moves down. \cite{foundations} examined 10 of these patterns and found overwhelming significance for the indicators when applied to the Nasdaq stock index. \cite{chang1999methodical} also find a Head-and-Shoulders pattern was profitable, but was outperformed by simpler trading rules such as a moving average indicator. Japanese Candlestick charting is considered to be identifying technical patterns.

\item Pivot points, Support and Resistance price levels which are very commonly calculated in industry but have not received significant academic attention \citep[p. 55]{osler2000support}. According to \cite{murphy1999technical}, a support level is ``a level or area on the chart under the market where buying interest is sufficiently strong to overcome selling pressure. As a result, a decline is halted and prices turn back up again''. Resistance is the opposite of support. Often they are levels where the price has had difficulty breaking before, either as static price points (such as the weekly low price) or points where the price meets a trend line that it appears to be bounding off. \cite{brock1992} found strong support for this style of trading strategy.

\end{itemize}

\section{Design}

AIM: To leave no doubt in the reader that I have done this correctly, and covered all bases.

\subsection{Motivations}

Very few visual chart pattern studies done, which is essentially what I'm finding. Fuzzy logic very applicable

There are relatively few Technical Analysis studies which identify visual patterns and attempt to evaluate their significance. This is an unexpected phenomenon as so many technical trader rely on visual pattern recognition in their strategy. One reason for this outlined by \cite{2020} is the challenge of ``automatic detection of technical patterns that would be similarly deducted by expert investors''. They make the point that the automated process would need to capture human cognitive abilities, even intuition...

idea: get fuzzy membership to each stdev and use that to determine significance. a pattern could belong to 2 patterns but the outcome will have a fuzzy membership value as dictated by the patterns belongingness to the fuzzy sequence. nb does increase patterns that would be recognised by 2n squared.
hmmmmm I could adapt the trend weighted model

severe limitation of my method is ignoring high and low, thus eliminating candlestick visual pattern significance

pattern discovery in time series uses bayes rule to determine probability

I am NOT doing the standard fts method, as I am analysing n patterns to results, instead of just 1 -> outcome - though perhaps some did it this way

\subsection{Time-Series analysis}

Discussion of the various papers that this is inspired from. The TAIEX paper, the univeristy enrollment paper,  the various dual factor fuzzy logic time series papers.

\subsection{Statistical Analysis of Data}

A clear picture was desired as to the significance of price movement. The use of z-scores in identifying price patterns was... (NB. This is different to previous papers that I am comparing to which makes comparisons difficult).

\subsection{Crisp Design}

Essentially how I applied the time series analysis to what I have right now (using rolling window, using time series methodology). This section may not be necessary.

\subsection{Fuzzy Logic Inference System}

\subsubsection{Justification of Design}

Why I did mandami for example (nb. not yet decided).

\subsection{Foreign Exchange}

In the past 30 years the foreign exchange markets has grown from an exclusive, locked down market to one of the most actively traded an qd liquid markets today. The market has many interesting properties compared to the more historically significant stock market, such as 24 hour trading, and the price being a good general reflection on the state of a country or unions economy. However, due to the recent surge in interest in this market it has not had the same level of study as the traditionally popular markets despite showing some interesting behaviours that may be of interest...

\cite{taprofitability} also found that different markets were better suited to Technical Analysis, with Foreign Exchange used in just under a third of the studies listed, and just under half of the modern studies listed. Interestingly they find that profits in this market seem to gradually decrease over time. This is also found by \cite{ttrp2006}, who suggest that the Foreign Exchange market has become more efficient in recent times.

\subsubsection{Implementation}

\subsection{Acquiring Data}

Data used was publicly available data obtained from [...]. The data was verified against several sources, and verified that data was complete. Data used was daily opening...

Step by step fuzzy logic system - fuzzification, inference, aggregation, defuzzification...

\section{Implementation}

...

\section{Results \& Evaluation}
Stand back and evaluate what you have achieved and how well you have met the objectives. Evaluate your achievements against your objectives in section 1.2. Demonstrate that you have tackled the project in a professional manner. 

alleviate data snooping by considering a diverse set of technical trading systems and conducting parameter optimisation and out of sample verification \citep{taprofitability}.

\subsection{RMSE Performance Indicator}

Outline how it has been used in other papers. Outline how we can draw direct comparisons...

\subsection{Results}

Results of the analysis of data. Show that the average price movement comes to approximately 0, as expected. Show the patterns discovered, show the significance of these using statistical analysis...

\subsubsection{Statistical significance of patterns}

Show the significance of certain patterns statistically using survey sampling techniques \& confidence interval...

\subsection{Forward testing}

See the error when testing against data that was not used to train the program...

\subsection{Comparisons}

Compare the results to previous papers.

\section{Conclusion}

Analysis of results against objectives...

\section{Future work}

What went well, what could be improved...

\bibliographystyle{plainnat}
\bibliography{dissertation}

\end{document}